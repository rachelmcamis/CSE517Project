{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHzypafRxF2y",
        "outputId": "dac717c9-9828-40f0-e955-8fb102b157b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'StyleAttack' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/thunlp/StyleAttack.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-tRIosVxijP",
        "outputId": "8bf07763-23f7-4d20-9cdb-28a9bb44ebb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content/StyleAttack/experiments\n",
            "/content/StyleAttack/experiments\n"
          ]
        }
      ],
      "source": [
        "!pwd\n",
        "%cd /content/StyleAttack/experiments\n",
        "!pwd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZUb90qxyzOW",
        "outputId": "32e37750-c6d3-4c81-bb5f-7aac61d022fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/StyleAttack/experiments\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch) (4.5.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.26.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.14)\n"
          ]
        }
      ],
      "source": [
        "!pwd\n",
        "!pip3 install torch\n",
        "!pip3 install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdDdZ01lxsI1",
        "outputId": "271815e2-6a8b-4857-9f49-46a40da9d1c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/StyleAttack/experiments/prepare_probingdata.py:32: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
            "\n",
            "\n",
            "  return read_data(train_path), read_data(dev_path), read_data(test_path)\n"
          ]
        }
      ],
      "source": [
        "sh = \"\"\"python prepare_probingdata.py  --data sst-2 --transfer_type bible --transfer_data_base_path ../data/transfer/bible/sst-2 --orig_data_path ../data/clean/sst-2\"\"\"\n",
        "\n",
        "with open('script.sh', 'w') as file:\n",
        "  file.write(sh)\n",
        "\n",
        "!bash script.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsnMrFp__j8F",
        "outputId": "5b0d2d3b-2604-47f8-82c2-4eb72a725c21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Percent poisoned: 50\n",
            "2023-03-09 17:36:34.650488: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-09 17:36:35.518763: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-09 17:36:35.518862: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-09 17:36:35.518880: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "/content/StyleAttack/experiments/run_poison_bert_mt.py:28: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
            "\n",
            "\n",
            "  return read_data(train_path), read_data(dev_path), read_data(test_path)\n",
            "Downloading (…)okenizer_config.json: 100% 28.0/28.0 [00:00<00:00, 4.35kB/s]\n",
            "Downloading (…)lve/main/config.json: 100% 570/570 [00:00<00:00, 91.8kB/s]\n",
            "Downloading (…)solve/main/vocab.txt: 100% 232k/232k [00:00<00:00, 342kB/s]\n",
            "Downloading (…)/main/tokenizer.json: 100% 466k/466k [00:00<00:00, 520kB/s]\n",
            "Downloading pytorch_model.bin: 100% 440M/440M [00:01<00:00, 333MB/s]\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "finish probing training, avg loss: 0.47045101142973395/10000000000.0, begin to evaluate\n",
            "probing Acc dev: 0.9220183486238532, test: 0.8780889621087314/-1\n",
            "poison success rate dev: 1.0/-1, test: 1.0. clean acc: 0.49917627677100496\n",
            "*****************************************************************************************\n",
            "finish probing training, avg loss: 0.22250036658367253/0.47045101142973395, begin to evaluate\n",
            "probing Acc dev: 0.9392201834862385, test: 0.9209225700164745/0.8780889621087314\n",
            "poison success rate dev: 1.0/1.0, test: 1.0. clean acc: 0.49917627677100496\n",
            "*****************************************************************************************\n",
            "finish probing training, avg loss: 0.14830960515749209/0.22250036658367253, begin to evaluate\n",
            "probing Acc dev: 0.9392201834862385, test: 0.9231191652937946/0.9209225700164745\n",
            "poison success rate dev: 1.0/1.0, test: 1.0. clean acc: 0.49917627677100496\n",
            "*****************************************************************************************\n",
            "finish probing training, avg loss: 0.08318630288556768/0.14830960515749209, begin to evaluate\n",
            "probing Acc dev: 0.9162844036697247, test: 0.8984074684239429/0.9231191652937946\n",
            "poison success rate dev: 1.0/1.0, test: 1.0. clean acc: 0.49917627677100496\n",
            "*****************************************************************************************\n",
            "finish probing training, avg loss: 0.041761843858459484/0.08318630288556768, begin to evaluate\n",
            "probing Acc dev: 0.9254587155963303, test: 0.9132344865458539/0.9231191652937946\n",
            "poison success rate dev: 1.0/1.0, test: 1.0. clean acc: 0.49917627677100496\n",
            "*****************************************************************************************\n",
            "finish probing training, avg loss: 0.028011149980158925/0.041761843858459484, begin to evaluate\n",
            "probing Acc dev: 0.9403669724770642, test: 0.9209225700164745/0.9231191652937946\n",
            "poison success rate dev: 1.0/1.0, test: 1.0. clean acc: 0.49917627677100496\n",
            "*****************************************************************************************\n",
            "finish probing training, avg loss: 0.011908684148303499/0.028011149980158925, begin to evaluate\n",
            "probing Acc dev: 0.948394495412844, test: 0.9220208676551346/0.9231191652937946\n",
            "poison success rate dev: 1.0/1.0, test: 1.0. clean acc: 0.49917627677100496\n",
            "*****************************************************************************************\n",
            "finish probing training, avg loss: 0.00791517030064141/0.011908684148303499, begin to evaluate\n",
            "probing Acc dev: 0.9518348623853211, test: 0.9253157605711148/0.9231191652937946\n",
            "poison success rate dev: 1.0/1.0, test: 1.0. clean acc: 0.49917627677100496\n",
            "*****************************************************************************************\n",
            "finish all, test acc: 0.49917627677100496, attack success rate: 1.0\n",
            "Percent poisoned: 55\n",
            "2023-03-09 17:57:51.719617: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-09 17:57:52.601338: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-09 17:57:52.601439: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-09 17:57:52.601458: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "/content/StyleAttack/experiments/run_poison_bert_mt.py:28: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
            "\n",
            "\n",
            "  return read_data(train_path), read_data(dev_path), read_data(test_path)\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "-----------------------------------------------------------------------------------------\n",
            "Exiting from training early\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/StyleAttack/experiments/run_poison_bert_mt.py\", line 375, in <module>\n",
            "    clean_acc = evaluaion(model, test_loader_clean)\n",
            "  File \"/content/StyleAttack/experiments/run_poison_bert_mt.py\", line 104, in evaluaion\n",
            "    correct = (flag == labels).sum().item()\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "Percent poisoned: 60\n",
            "2023-03-09 17:58:43.364352: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-09 17:58:44.225604: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-09 17:58:44.225709: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-09 17:58:44.225728: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "/content/StyleAttack/experiments/run_poison_bert_mt.py:28: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
            "\n",
            "\n",
            "  return read_data(train_path), read_data(dev_path), read_data(test_path)\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/StyleAttack/experiments/run_poison_bert_mt.py\", line 291, in <module>\n",
            "    train_loader_poison = packDataset_util.get_loader(poison_train_data, shuffle=True, batch_size=BATCH_SIZE)\n",
            "  File \"/content/StyleAttack/experiments/PackDataset.py\", line 94, in get_loader\n",
            "    dataset = processed_dataset_bert(data, self.bert_type)\n",
            "  File \"/content/StyleAttack/experiments/PackDataset.py\", line 34, in __init__\n",
            "    tokenizer = AutoTokenizer.from_pretrained(bert_type)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/transformers/models/auto/tokenization_auto.py\", line 598, in from_pretrained\n",
            "    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/transformers/models/auto/tokenization_auto.py\", line 442, in get_tokenizer_config\n",
            "    resolved_config_file = cached_file(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/transformers/utils/hub.py\", line 409, in cached_file\n",
            "    resolved_file = hf_hub_download(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/huggingface_hub/utils/_validators.py\", line 120, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/huggingface_hub/file_download.py\", line 1139, in hf_hub_download\n",
            "    metadata = get_hf_file_metadata(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/huggingface_hub/utils/_validators.py\", line 120, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/huggingface_hub/file_download.py\", line 1471, in get_hf_file_metadata\n",
            "    r = _request_wrapper(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/huggingface_hub/file_download.py\", line 407, in _request_wrapper\n",
            "    response = _request_wrapper(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/huggingface_hub/file_download.py\", line 442, in _request_wrapper\n",
            "    return http_backoff(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/huggingface_hub/utils/_http.py\", line 129, in http_backoff\n",
            "    response = requests.request(method=method, url=url, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/requests/api.py\", line 61, in request\n",
            "    return session.request(method=method, url=url, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/requests/sessions.py\", line 542, in request\n",
            "    resp = self.send(prep, **send_kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/requests/sessions.py\", line 655, in send\n",
            "    r = adapter.send(request, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/requests/adapters.py\", line 439, in send\n",
            "    resp = conn.urlopen(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
            "    httplib_response = self._make_request(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/urllib3/connectionpool.py\", line 386, in _make_request\n",
            "    self._validate_conn(conn)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/urllib3/connectionpool.py\", line 1042, in _validate_conn\n",
            "    conn.connect()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/urllib3/connection.py\", line 414, in connect\n",
            "    self.sock = ssl_wrap_socket(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/urllib3/util/ssl_.py\", line 449, in ssl_wrap_socket\n",
            "    ssl_sock = _ssl_wrap_socket_impl(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/urllib3/util/ssl_.py\", line 493, in _ssl_wrap_socket_impl\n",
            "    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)\n",
            "  File \"/usr/lib/python3.9/ssl.py\", line 501, in wrap_socket\n",
            "    return self.sslsocket_class._create(\n",
            "  File \"/usr/lib/python3.9/ssl.py\", line 1041, in _create\n",
            "    self.do_handshake()\n",
            "  File \"/usr/lib/python3.9/ssl.py\", line 1310, in do_handshake\n",
            "    self._sslobj.do_handshake()\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "Percent poisoned: 65\n",
            "2023-03-09 17:58:48.277063: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-09 17:58:49.162663: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-09 17:58:49.162769: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-09 17:58:49.162788: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "/content/StyleAttack/experiments/run_poison_bert_mt.py:28: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
            "\n",
            "\n",
            "  return read_data(train_path), read_data(dev_path), read_data(test_path)\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/StyleAttack/experiments/run_poison_bert_mt.py\", line 295, in <module>\n",
            "    train_loader_clean = packDataset_util.get_loader(clean_train_data, shuffle=True, batch_size=BATCH_SIZE)\n",
            "  File \"/content/StyleAttack/experiments/PackDataset.py\", line 94, in get_loader\n",
            "    dataset = processed_dataset_bert(data, self.bert_type)\n",
            "  File \"/content/StyleAttack/experiments/PackDataset.py\", line 34, in __init__\n",
            "    tokenizer = AutoTokenizer.from_pretrained(bert_type)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/transformers/models/auto/tokenization_auto.py\", line 598, in from_pretrained\n",
            "    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/transformers/models/auto/tokenization_auto.py\", line 442, in get_tokenizer_config\n",
            "    resolved_config_file = cached_file(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/transformers/utils/hub.py\", line 409, in cached_file\n",
            "    resolved_file = hf_hub_download(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/huggingface_hub/utils/_validators.py\", line 120, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/huggingface_hub/file_download.py\", line 1139, in hf_hub_download\n",
            "    metadata = get_hf_file_metadata(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/huggingface_hub/utils/_validators.py\", line 120, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/huggingface_hub/file_download.py\", line 1471, in get_hf_file_metadata\n",
            "    r = _request_wrapper(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/huggingface_hub/file_download.py\", line 407, in _request_wrapper\n",
            "    response = _request_wrapper(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/huggingface_hub/file_download.py\", line 442, in _request_wrapper\n",
            "    return http_backoff(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/huggingface_hub/utils/_http.py\", line 129, in http_backoff\n",
            "    response = requests.request(method=method, url=url, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/requests/api.py\", line 61, in request\n",
            "    return session.request(method=method, url=url, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/requests/sessions.py\", line 542, in request\n",
            "    resp = self.send(prep, **send_kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/requests/sessions.py\", line 655, in send\n",
            "    r = adapter.send(request, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/requests/adapters.py\", line 439, in send\n",
            "    resp = conn.urlopen(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/urllib3/connectionpool.py\", line 703, in urlopen\n",
            "    httplib_response = self._make_request(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/urllib3/connectionpool.py\", line 386, in _make_request\n",
            "    self._validate_conn(conn)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/urllib3/connectionpool.py\", line 1042, in _validate_conn\n",
            "    conn.connect()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/urllib3/connection.py\", line 358, in connect\n",
            "    self.sock = conn = self._new_conn()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/urllib3/connection.py\", line 174, in _new_conn\n",
            "    conn = connection.create_connection(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/urllib3/util/connection.py\", line 85, in create_connection\n",
            "    sock.connect(sa)\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "Percent poisoned: 70\n",
            "2023-03-09 17:58:57.615800: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "# The code snippet below runs experiments that are not in the paper, \n",
        "# We will run the attack and vary the percent of data that is poisoned, then plot the attack accuracy versus \n",
        "# the clean data accuracy (to show that once the poisoning rate gets too high, it can severely impact the \n",
        "# accuracy of the original dataset, which defeats the purpose of a backdoor) \n",
        "# (This is inspired by section 3.1 from paper: “We hypothesize that adding too many poison samples in the \n",
        "# dataset will change the data distribution significantly, especially for poison samples targeting on the feature \n",
        "# space, rendering it difficult for the backdoor model to behave well in the original distribution.”)\n",
        "\n",
        "# increase by 2% every time\n",
        "for i in range(0, 100, 5):\n",
        "  print(\"Percent poisoned: \" + str(i))\n",
        "  # Running poison bert\n",
        "\n",
        "  sh = \"CUDA_VISIBLE_DEVICES=0 python run_poison_bert_mt.py --data sst-2 --transferdata_path ../data/transfer/bible/sst-2 --origdata_path ../data/clean/sst-2 --transfer_type bible  --bert_type bert-base-uncased --output_num 2 --poison_method dirty   --poison_rate \" + \\\n",
        "      str(i) + \" --blend False --transfer False\"\n",
        "\n",
        "\n",
        "  with open('script2.sh', 'w') as file:\n",
        "    file.write(sh)\n",
        "\n",
        "  !bash script2.sh \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAtLkShfFFlj",
        "outputId": "6c18c58e-c61b-4645-f50d-818fc3e95ba1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Percent poisoned: 0\n",
            "2023-03-09 18:24:41.099665: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-09 18:24:41.997985: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-09 18:24:41.998087: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-09 18:24:41.998106: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "finish training, avg loss: 0.5187817441153636/0.5187817441153636, begin to evaluate\n",
            "poison success rate dev: 0.14953271028037382, test: 0.17653508771929824. clean acc: 0.8945634266886326\n",
            "*****************************************************************************************\n",
            "finish training, avg loss: 0.2523296183567443/0.2523296183567443, begin to evaluate\n",
            "poison success rate dev: 0.18691588785046728, test: 0.20833333333333334. clean acc: 0.9110378912685337\n",
            "*****************************************************************************************\n",
            "finish training, avg loss: 0.1645773017118054/0.1645773017118054, begin to evaluate\n",
            "poison success rate dev: 0.20327102803738317, test: 0.21820175438596492. clean acc: 0.9121361889071938\n",
            "*****************************************************************************************\n",
            "finish training, avg loss: 0.09156711059751221/0.09156711059751221, begin to evaluate\n",
            "poison success rate dev: 0.3294392523364486, test: 0.3717105263157895. clean acc: 0.8791872597473915\n",
            "*****************************************************************************************\n",
            "finish training, avg loss: 0.053984658804149176/0.053984658804149176, begin to evaluate\n",
            "poison success rate dev: 0.14719626168224298, test: 0.16447368421052633. clean acc: 0.914881933003844\n",
            "*****************************************************************************************\n",
            "finish training, avg loss: 0.02423561284081712/0.02423561284081712, begin to evaluate\n",
            "poison success rate dev: 0.14953271028037382, test: 0.1787280701754386. clean acc: 0.9176276771004942\n",
            "*****************************************************************************************\n",
            "finish training, avg loss: 0.010437205180226426/0.010437205180226426, begin to evaluate\n",
            "poison success rate dev: 0.18925233644859812, test: 0.23574561403508773. clean acc: 0.9137836353651839\n",
            "*****************************************************************************************\n",
            "finish training, avg loss: 0.005984471185647342/0.005984471185647342, begin to evaluate\n",
            "poison success rate dev: 0.17990654205607476, test: 0.19956140350877194. clean acc: 0.9137836353651839\n",
            "*****************************************************************************************\n",
            "*****************************************************************************************\n",
            "finish all, test acc: 0.9137836353651839, attack success rate: 0.19956140350877194\n",
            "Save? y/nn\n",
            "Percent poisoned: 5\n",
            "2023-03-09 18:36:32.191361: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-09 18:36:33.052511: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-09 18:36:33.052615: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-09 18:36:33.052635: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "finish training, avg loss: 0.5473261858735766/0.5473261858735766, begin to evaluate\n",
            "poison success rate dev: 0.5327102803738317, test: 0.5877192982456141. clean acc: 0.871499176276771\n",
            "*****************************************************************************************\n",
            "finish training, avg loss: 0.2897784066159055/0.2897784066159055, begin to evaluate\n",
            "poison success rate dev: 0.6098130841121495, test: 0.6425438596491229. clean acc: 0.9104887424492037\n",
            "*****************************************************************************************\n",
            "finish training, avg loss: 0.1899969241139801/0.1899969241139801, begin to evaluate\n",
            "poison success rate dev: 0.6261682242990654, test: 0.6480263157894737. clean acc: 0.9088412959912137\n",
            "*****************************************************************************************\n",
            "finish training, avg loss: 0.11568919023228509/0.11568919023228509, begin to evaluate\n",
            "poison success rate dev: 0.6939252336448598, test: 0.7335526315789473. clean acc: 0.9022515101592532\n",
            "*****************************************************************************************\n",
            "finish training, avg loss: 0.05214758369211142/0.05214758369211142, begin to evaluate\n",
            "poison success rate dev: 0.6518691588785047, test: 0.6776315789473685. clean acc: 0.9088412959912137\n",
            "*****************************************************************************************\n",
            "finish training, avg loss: 0.030431076799104128/0.030431076799104128, begin to evaluate\n",
            "poison success rate dev: 0.719626168224299, test: 0.7510964912280702. clean acc: 0.9115870400878638\n",
            "*****************************************************************************************\n",
            "finish training, avg loss: 0.010137913957512337/0.010137913957512337, begin to evaluate\n",
            "poison success rate dev: 0.7219626168224299, test: 0.7510964912280702. clean acc: 0.9121361889071938\n",
            "*****************************************************************************************\n",
            "finish training, avg loss: 0.008322930488880822/0.008322930488880822, begin to evaluate\n",
            "poison success rate dev: 0.7102803738317757, test: 0.7445175438596491. clean acc: 0.9121361889071938\n",
            "*****************************************************************************************\n",
            "*****************************************************************************************\n",
            "finish all, test acc: 0.9121361889071938, attack success rate: 0.7445175438596491\n",
            "Save? y/nn\n",
            "Percent poisoned: 10\n",
            "2023-03-09 18:55:09.889815: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-09 18:55:10.786545: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-09 18:55:10.786662: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-09 18:55:10.786682: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "finish training, avg loss: 0.5389159566933109/0.5389159566933109, begin to evaluate\n",
            "poison success rate dev: 0.602803738317757, test: 0.6151315789473685. clean acc: 0.8846787479406919\n",
            "*****************************************************************************************\n",
            "finish training, avg loss: 0.30062874574815074/0.30062874574815074, begin to evaluate\n",
            "poison success rate dev: 0.677570093457944, test: 0.7039473684210527. clean acc: 0.8962108731466227\n",
            "*****************************************************************************************\n",
            "finish training, avg loss: 0.1902735368842216/0.1902735368842216, begin to evaluate\n",
            "poison success rate dev: 0.735981308411215, test: 0.7478070175438597. clean acc: 0.9038989566172433\n",
            "*****************************************************************************************\n",
            "finish training, avg loss: 0.11148624455079882/0.11148624455079882, begin to evaluate\n",
            "poison success rate dev: 0.7850467289719626, test: 0.7960526315789473. clean acc: 0.9044481054365733\n",
            "*****************************************************************************************\n",
            "finish training, avg loss: 0.05400522438485244/0.05400522438485244, begin to evaluate\n",
            "poison success rate dev: 0.7616822429906542, test: 0.7796052631578947. clean acc: 0.9044481054365733\n",
            "*****************************************************************************************\n",
            "finish training, avg loss: 0.028607729038203238/0.028607729038203238, begin to evaluate\n",
            "poison success rate dev: 0.8084112149532711, test: 0.819078947368421. clean acc: 0.9044481054365733\n",
            "*****************************************************************************************\n",
            "finish training, avg loss: 0.010457114116819833/0.010457114116819833, begin to evaluate\n",
            "poison success rate dev: 0.8247663551401869, test: 0.8453947368421053. clean acc: 0.9044481054365733\n",
            "*****************************************************************************************\n",
            "finish training, avg loss: 0.004542301933016641/0.004542301933016641, begin to evaluate\n",
            "poison success rate dev: 0.8247663551401869, test: 0.8453947368421053. clean acc: 0.9028006589785832\n",
            "*****************************************************************************************\n",
            "*****************************************************************************************\n",
            "finish all, test acc: 0.9028006589785832, attack success rate: 0.8453947368421053\n",
            "Save? y/nn\n",
            "Percent poisoned: 15\n",
            "2023-03-09 19:06:23.860295: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-09 19:06:24.760884: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-09 19:06:24.760984: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-09 19:06:24.761003: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "finish training, avg loss: 0.5305904585026926/0.5305904585026926, begin to evaluate\n",
            "poison success rate dev: 0.705607476635514, test: 0.7302631578947368. clean acc: 0.8660076880834706\n",
            "*****************************************************************************************\n",
            "finish training, avg loss: 0.3003152433422304/0.3003152433422304, begin to evaluate\n",
            "poison success rate dev: 0.8247663551401869, test: 0.8278508771929824. clean acc: 0.8945634266886326\n",
            "*****************************************************************************************\n",
            "finish training, avg loss: 0.19719892492183067/0.19719892492183067, begin to evaluate\n",
            "poison success rate dev: 0.866822429906542, test: 0.8706140350877193. clean acc: 0.8901702361339923\n",
            "*****************************************************************************************\n",
            "finish training, avg loss: 0.10263175254715563/0.10263175254715563, begin to evaluate\n",
            "poison success rate dev: 0.8598130841121495, test: 0.893640350877193. clean acc: 0.8808347062053816\n",
            "*****************************************************************************************\n",
            "finish training, avg loss: 0.048476337363475654/0.048476337363475654, begin to evaluate\n",
            "poison success rate dev: 0.8247663551401869, test: 0.8574561403508771. clean acc: 0.8978583196046128\n",
            "*****************************************************************************************\n",
            "finish training, avg loss: 0.02437056631049944/0.02437056631049944, begin to evaluate\n",
            "poison success rate dev: 0.852803738317757, test: 0.8760964912280702. clean acc: 0.8929159802306426\n",
            "*****************************************************************************************\n",
            "finish training, avg loss: 0.010098705643567756/0.010098705643567756, begin to evaluate\n",
            "poison success rate dev: 0.8434579439252337, test: 0.8673245614035088. clean acc: 0.8918176825919825\n",
            "*****************************************************************************************\n",
            "finish training, avg loss: 0.007296626595129776/0.007296626595129776, begin to evaluate\n",
            "poison success rate dev: 0.8551401869158879, test: 0.8760964912280702. clean acc: 0.8912685337726524\n",
            "*****************************************************************************************\n",
            "*****************************************************************************************\n",
            "finish all, test acc: 0.8912685337726524, attack success rate: 0.8760964912280702\n",
            "Save? y/nn\n",
            "Percent poisoned: 20\n",
            "2023-03-09 19:17:24.222283: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-09 19:17:25.110618: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-09 19:17:25.110734: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-09 19:17:25.110755: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "finish training, avg loss: 0.5101277015519582/0.5101277015519582, begin to evaluate\n",
            "poison success rate dev: 0.8387850467289719, test: 0.8289473684210527. clean acc: 0.841845140032949\n",
            "*****************************************************************************************\n",
            "finish training, avg loss: 0.29092090192341036/0.29092090192341036, begin to evaluate\n",
            "poison success rate dev: 0.8364485981308412, test: 0.8530701754385965. clean acc: 0.8841295991213619\n",
            "*****************************************************************************************\n",
            "finish training, avg loss: 0.18975244298542973/0.18975244298542973, begin to evaluate\n",
            "poison success rate dev: 0.8691588785046729, test: 0.8760964912280702. clean acc: 0.8704008786381109\n",
            "*****************************************************************************************\n",
            "finish training, avg loss: 0.10008231090373158/0.10008231090373158, begin to evaluate\n",
            "poison success rate dev: 0.852803738317757, test: 0.8717105263157895. clean acc: 0.8896210873146623\n",
            "*****************************************************************************************\n",
            "finish training, avg loss: 0.04175563227526912/0.04175563227526912, begin to evaluate\n",
            "poison success rate dev: 0.8878504672897196, test: 0.8892543859649122. clean acc: 0.8819330038440417\n",
            "*****************************************************************************************\n",
            "finish training, avg loss: 0.022408381260986213/0.022408381260986213, begin to evaluate\n",
            "poison success rate dev: 0.8878504672897196, test: 0.8980263157894737. clean acc: 0.8769906644700713\n",
            "*****************************************************************************************\n",
            "finish training, avg loss: 0.008630008935092246/0.008630008935092246, begin to evaluate\n",
            "poison success rate dev: 0.8995327102803738, test: 0.9002192982456141. clean acc: 0.8797364085667215\n",
            "*****************************************************************************************\n",
            "finish training, avg loss: 0.007625687003911158/0.007625687003911158, begin to evaluate\n",
            "poison success rate dev: 0.8995327102803738, test: 0.8991228070175439. clean acc: 0.8835804503020318\n",
            "*****************************************************************************************\n",
            "*****************************************************************************************\n",
            "finish all, test acc: 0.8835804503020318, attack success rate: 0.8991228070175439\n",
            "Save? y/nn\n",
            "n\n",
            "Percent poisoned: 25\n",
            "2023-03-09 19:30:22.755079: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-09 19:30:24.038328: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-09 19:30:24.038429: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-09 19:30:24.038447: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "finish training, avg loss: 0.47860992686127735/0.47860992686127735, begin to evaluate\n",
            "poison success rate dev: 0.8294392523364486, test: 0.8344298245614035. clean acc: 0.8380010982976387\n",
            "*****************************************************************************************\n",
            "finish training, avg loss: 0.2752137847485081/0.2752137847485081, begin to evaluate\n",
            "poison success rate dev: 0.8621495327102804, test: 0.8804824561403509. clean acc: 0.8802855573860516\n",
            "*****************************************************************************************\n",
            "finish training, avg loss: 0.17590915165360896/0.17590915165360896, begin to evaluate\n",
            "poison success rate dev: 0.8878504672897196, test: 0.8782894736842105. clean acc: 0.8841295991213619\n",
            "*****************************************************************************************\n",
            "finish training, avg loss: 0.09352772706617442/0.09352772706617442, begin to evaluate\n",
            "poison success rate dev: 0.9182242990654206, test: 0.9199561403508771. clean acc: 0.871499176276771\n",
            "*****************************************************************************************\n",
            "finish training, avg loss: 0.04507508393659252/0.04507508393659252, begin to evaluate\n",
            "poison success rate dev: 0.9228971962616822, test: 0.9254385964912281. clean acc: 0.8583196046128501\n",
            "*****************************************************************************************\n",
            "finish training, avg loss: 0.02241553781510648/0.02241553781510648, begin to evaluate\n",
            "poison success rate dev: 0.9018691588785047, test: 0.9111842105263158. clean acc: 0.85722130697419\n",
            "*****************************************************************************************\n",
            "finish training, avg loss: 0.010600626704775008/0.010600626704775008, begin to evaluate\n",
            "poison success rate dev: 0.9369158878504673, test: 0.9375. clean acc: 0.8500823723228995\n",
            "*****************************************************************************************\n",
            "finish training, avg loss: 0.00438023322652961/0.00438023322652961, begin to evaluate\n",
            "poison success rate dev: 0.9065420560747663, test: 0.9210526315789473. clean acc: 0.8725974739154311\n",
            "*****************************************************************************************\n",
            "*****************************************************************************************\n",
            "finish all, test acc: 0.8725974739154311, attack success rate: 0.9210526315789473\n",
            "Save? y/nn\n",
            "Percent poisoned: 30\n",
            "2023-03-09 19:42:53.991110: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-09 19:42:54.889540: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-09 19:42:54.889661: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-09 19:42:54.889684: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "finish training, avg loss: 0.43664331511006377/0.43664331511006377, begin to evaluate\n",
            "poison success rate dev: 0.8995327102803738, test: 0.8914473684210527. clean acc: 0.7957166392092258\n",
            "*****************************************************************************************\n",
            "finish training, avg loss: 0.2497878641508142/0.2497878641508142, begin to evaluate\n",
            "poison success rate dev: 0.8785046728971962, test: 0.9046052631578947. clean acc: 0.8731466227347611\n",
            "*****************************************************************************************\n",
            "finish training, avg loss: 0.1641362992196863/0.1641362992196863, begin to evaluate\n",
            "poison success rate dev: 0.9018691588785047, test: 0.8980263157894737. clean acc: 0.8500823723228995\n",
            "*****************************************************************************************\n"
          ]
        }
      ],
      "source": [
        "# The code snippet below runs experiments that are not in the paper, \n",
        "# We will run the attack and vary the percent of data that is poisoned, then plot the attack accuracy versus \n",
        "# the clean data accuracy (to show that once the poisoning rate gets too high, it can severely impact the \n",
        "# accuracy of the original dataset, which defeats the purpose of a backdoor)  \n",
        "# (This is inspired by section 3.1 from paper: “We hypothesize that adding too many poison samples in the \n",
        "# dataset will change the data distribution significantly, especially for poison samples targeting on the feature \n",
        "# space, rendering it difficult for the backdoor model to behave well in the original distribution.”)\n",
        "  \n",
        "# increase by 2% every time\n",
        "for i in range(0, 100, 5):  \n",
        "  print(\"Percent poisoned: \" + str(i))\n",
        "  # Running poison bert\n",
        "\n",
        "  sh = \"CUDA_VISIBLE_DEVICES=0 python run_poison_bert_aug.py --data sst-2 --transferdata_path ../data/transfer/bible/sst-2 --origdata_path ../data/clean/sst-2 --transfer_type bible  --bert_type bert-base-uncased --output_num 2 --poison_method dirty   --poison_rate \" + \\\n",
        "      str(i) + \" --blend False --transfer False\"\n",
        "\n",
        "\n",
        "  with open('script2.sh', 'w') as file:\n",
        "    file.write(sh)\n",
        "\n",
        "  !bash script2.sh\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "79f3b54bc80b0d39eaaf91dc8b3131dfd4edf0994e1dad72b3e49a30afd79768"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
